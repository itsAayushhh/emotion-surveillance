<div align="center">

<!-- Hero Banner -->
<img src="https://capsule-render.vercel.app/api?type=waving&color=0:0a0a20,50:00f3ff,100:bc13fe&height=220&section=header&text=SURVI&fontSize=80&fontColor=ffffff&fontAlignY=35&desc=Emotion%20Surveillance%20System&descSize=20&descAlignY=55&animation=fadeIn" width="100%" />

<br/>

<!-- Badges -->
[![Next.js](https://img.shields.io/badge/Next.js-16-black?style=for-the-badge&logo=next.js&logoColor=white)](https://nextjs.org/)
[![React](https://img.shields.io/badge/React-19-61DAFB?style=for-the-badge&logo=react&logoColor=black)](https://react.dev/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)](https://www.tensorflow.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.x-3178C6?style=for-the-badge&logo=typescript&logoColor=white)](https://typescriptlang.org/)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-4.x-06B6D4?style=for-the-badge&logo=tailwindcss&logoColor=white)](https://tailwindcss.com/)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

<br/>

<p align="center">
  <strong>ğŸ§  A real-time facial emotion recognition system powered by deep learning, featuring a cinematic dark-themed dashboard with 3D glassmorphism UI, Grad-CAM interpretability, and interactive data visualizations.</strong>
</p>

<br/>

<!-- Animated Divider -->
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">

</div>

<br/>

## ğŸ¯ Overview

**SURVI** is an end-to-end emotion surveillance platform that combines a **custom-trained CNN model** on the **FER2013 dataset** with a stunning, production-grade dashboard. Upload any face image and get instant emotion predictions with confidence scores, Grad-CAM heatmap visualizations, face bounding boxes, and interactive analytics â€” all wrapped in a sleek cyberpunk-themed interface.

<br/>

<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   ğŸ“¸ Image Upload  â†’  ğŸ” Face Detection  â†’  ğŸ§  CNN Model   â”‚
â”‚                                                             â”‚
â”‚   â†’  ğŸ“Š Emotion Prediction  â†’  ğŸ”¥ Grad-CAM Heatmap         â”‚
â”‚                                                             â”‚
â”‚   â†’  ğŸ“ˆ Interactive Dashboard Visualizations                â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

<br/>

## âœ¨ Key Features

<table>
<tr>
<td width="50%">

### ğŸ§  Deep Learning Engine
- Custom **CNN architecture** trained on FER2013
- **7 emotion classes**: Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral
- **Haar Cascade** face detection with adaptive fallback
- **Grad-CAM** heatmap visualization for model interpretability
- Confidence scores for all emotion classes

</td>
<td width="50%">

### ğŸ¨ Cinematic Dashboard
- **Dark glassmorphism** UI with neon cyan/purple accents
- **3D interactive** auth page with perspective tilt effects
- **Animated particle** backgrounds and glowing orbs
- **Framer Motion** page transitions and micro-animations
- **Responsive** 2Ã—2 grid layout with collapsible sidebar

</td>
</tr>
<tr>
<td width="50%">

### ğŸ“Š Analytics & Visualizations
- **Interactive bar charts** â€” per-class accuracy breakdown
- **Training curves** â€” loss/accuracy line charts per epoch
- **Confusion matrix** â€” class-wise prediction heatmap
- **Dataset overview** â€” class distribution and statistics
- **Waveform visualizer** â€” decorative audio-wave component

</td>
<td width="50%">

### ğŸ” Auth & Architecture
- **JWT-based authentication** with signup/login
- **Next.js API routes** as backend proxy (no CORS issues)
- **FastAPI** Python backend for model inference
- **Image crop tool** â€” draw-to-select face region before analysis
- **Heatmap toggle** â€” switch between original and Grad-CAM view

</td>
</tr>
</table>

<br/>

<div align="center">
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">
</div>

<br/>

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    subgraph Frontend ["ğŸ–¥ï¸ Frontend â€” Next.js 16"]
        A[Auth Page<br/>3D Glassmorphism] --> B[Dashboard Layout<br/>Collapsible Sidebar]
        B --> C[Emotion Detection Panel<br/>Upload + Crop + Analyze]
        B --> D[Performance Panel<br/>Accuracy Metrics]
        B --> E[Training Analysis Panel<br/>Loss & Accuracy Curves]
        B --> F[Dataset Overview Panel<br/>Class Distribution]
    end

    subgraph API ["âš¡ API Layer"]
        G[Next.js API Routes<br/>/api/predict, /api/auth/*]
    end

    subgraph Backend ["ğŸ Backend â€” FastAPI"]
        H[FER2013 CNN Model<br/>TensorFlow/Keras]
        I[Face Detection<br/>OpenCV Haar Cascade]
        J[Grad-CAM Engine<br/>Heatmap Generation]
        K[Auth Service<br/>JWT Tokens]
    end

    C -->|Image Upload| G
    G -->|Proxy Request| H
    H --> I --> J
    A -->|Login/Signup| G
    G --> K

    style Frontend fill:#0a0a20,stroke:#00f3ff,color:#ffffff
    style API fill:#1a1a2e,stroke:#bc13fe,color:#ffffff
    style Backend fill:#0a0a20,stroke:#00f3ff,color:#ffffff
```

<br/>

## ğŸ› ï¸ Tech Stack

<div align="center">

| Layer | Technology | Purpose |
|:---:|:---:|:---|
| **Frontend** | Next.js 16, React 19, TypeScript | Core web framework & UI |
| **Styling** | Tailwind CSS 4, Custom CSS | Dark glassmorphism theme |
| **Animation** | Framer Motion | Page transitions & micro-interactions |
| **3D** | React Three Fiber, Three.js | 3D scene components |
| **Icons** | Lucide React | Consistent icon system |
| **Backend** | FastAPI, Uvicorn | REST API for model inference |
| **ML Model** | TensorFlow / Keras | FER2013 emotion classification CNN |
| **Vision** | OpenCV, Pillow | Face detection & image processing |
| **Data** | NumPy, Pandas, scikit-learn | Training data pipeline & evaluation |
| **Dataset** | FER2013 (via KaggleHub) | 35,887 grayscale 48Ã—48 face images |

</div>

<br/>

<div align="center">
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">
</div>

<br/>

## ğŸ“ Project Structure

```
emotion-surveillance/
â”‚
â”œâ”€â”€ emotion-dashboard/              # Main application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx            # Entry point â€” auth gate + dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx          # Root layout with metadata
â”‚   â”‚   â”‚   â”œâ”€â”€ globals.css         # Global styles & theme tokens
â”‚   â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚   â”‚       â”œâ”€â”€ predict/        # POST /api/predict â€” emotion inference
â”‚   â”‚   â”‚       â””â”€â”€ auth/           # POST /api/auth/login & signup
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth-page.tsx       # 3D interactive login/signup
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard-layout.tsx# Sidebar + header layout
â”‚   â”‚   â”‚   â”œâ”€â”€ panels/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ emotion-detection-panel.tsx  # Image upload + crop + analysis
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ performance-panel.tsx        # Model accuracy metrics
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ training-analysis-panel.tsx  # Training curves
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ dataset-overview-panel.tsx   # Dataset statistics
â”‚   â”‚   â”‚   â”œâ”€â”€ visualizations/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ bar-chart.tsx       # Interactive bar chart
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ line-chart.tsx      # Multi-line training chart
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ confusion-matrix.tsx# Heatmap confusion matrix
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ heatmap.tsx         # Generic heatmap component
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ waveform.tsx        # Animated waveform
â”‚   â”‚   â”‚   â””â”€â”€ ui/
â”‚   â”‚   â”‚       â””â”€â”€ glass-panel.tsx     # Reusable glassmorphism container
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ lib/
â”‚   â”‚       â”œâ”€â”€ auth-context.tsx    # React context for auth state
â”‚   â”‚       â”œâ”€â”€ auth-helpers.ts     # Token management utilities
â”‚   â”‚       â”œâ”€â”€ mock-data.ts        # Fallback data & color mappings
â”‚   â”‚       â””â”€â”€ types.ts            # TypeScript interfaces
â”‚   â”‚
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI server â€” prediction + Grad-CAM
â”‚   â”‚   â”œâ”€â”€ auth.py                 # JWT auth service
â”‚   â”‚   â”œâ”€â”€ train_model.py          # FER2013 CNN training script
â”‚   â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”‚   â””â”€â”€ model/                  # Trained model artifacts
â”‚   â”‚
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ next.config.ts
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

<br/>

## ğŸš€ Getting Started

### Prerequisites

- **Node.js** â‰¥ 18.x
- **Python** â‰¥ 3.10
- **npm** or **yarn**

---

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/itsAayushhh/emotion-surveillance.git
cd emotion-surveillance
```

### 2ï¸âƒ£ Setup Frontend

```bash
cd emotion-dashboard
npm install
```

### 3ï¸âƒ£ Setup Backend

```bash
cd backend
pip install -r requirements.txt
```

### 4ï¸âƒ£ Train the Model *(first time only)*

```bash
python train_model.py
```

> This downloads the FER2013 dataset from Kaggle, trains the CNN, and saves the model + metrics to the `model/` directory.

### 5ï¸âƒ£ Start the Backend Server

```bash
python main.py
```

The API will be available at `http://localhost:8000`

### 6ï¸âƒ£ Start the Frontend

```bash
# In the emotion-dashboard directory
npm run dev
```

Open **[http://localhost:3000](http://localhost:3000)** in your browser.

<br/>

<div align="center">
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">
</div>

<br/>

## ğŸ§ª API Endpoints

| Method | Endpoint | Description |
|:---:|:---|:---|
| `GET` | `/` | Health check â€” model status |
| `POST` | `/predict` | Upload image â†’ get emotion prediction + Grad-CAM |
| `POST` | `/auth/signup` | Create new user account |
| `POST` | `/auth/login` | Authenticate and receive JWT token |
| `GET` | `/auth/me` | Get current user from Bearer token |
| `GET` | `/metrics` | Training metrics & confusion matrix |
| `GET` | `/training-history` | Per-epoch accuracy & loss history |

<br/>

## ğŸ­ Supported Emotions

<div align="center">

| Emotion | Color | Description |
|:---:|:---:|:---|
| ğŸ˜  **Angry** | ğŸ”´ `#ff4444` | Expressions of anger or frustration |
| ğŸ¤¢ **Disgust** | ğŸŸ¢ `#44ff44` | Expressions of disgust or displeasure |
| ğŸ˜¨ **Fear** | ğŸŸ£ `#ff44ff` | Expressions of fear or anxiety |
| ğŸ˜Š **Happy** | ğŸŸ¡ `#ffff44` | Expressions of happiness or joy |
| ğŸ˜¢ **Sad** | ğŸ”µ `#4444ff` | Expressions of sadness or sorrow |
| ğŸ˜² **Surprise** | ğŸŸ  `#ff8844` | Expressions of surprise or shock |
| ğŸ˜ **Neutral** | âšª `#aaaaaa` | Neutral or baseline expressions |

</div>

<br/>

## ğŸ”¬ Model Details

<div align="center">

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           FER2013 CNN Architecture           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                              â•‘
â•‘   Input: 48Ã—48Ã—1 (Grayscale)                 â•‘
â•‘       â†“                                      â•‘
â•‘   Conv2D â†’ BatchNorm â†’ ReLU â†’ MaxPool        â•‘
â•‘       â†“                                      â•‘
â•‘   Conv2D â†’ BatchNorm â†’ ReLU â†’ MaxPool        â•‘
â•‘       â†“                                      â•‘
â•‘   Conv2D â†’ BatchNorm â†’ ReLU â†’ MaxPool        â•‘
â•‘       â†“                                      â•‘
â•‘   Flatten â†’ Dense â†’ Dropout                  â•‘
â•‘       â†“                                      â•‘
â•‘   Dense(7) â†’ Softmax                         â•‘
â•‘       â†“                                      â•‘
â•‘   Output: 7 Emotion Probabilities            â•‘
â•‘                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

</div>

- **Dataset**: FER2013 â€” 35,887 labeled face images (48Ã—48 grayscale)
- **Classes**: 7 (Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral)
- **Interpretability**: Grad-CAM heatmaps highlighting facial regions that drive predictions
- **Face Detection**: OpenCV Haar Cascade with adaptive parameters and fallback

<br/>

## ğŸ¨ Design Philosophy

<div align="center">

| Principle | Implementation |
|:---|:---|
| **Dark Cyberpunk** | Deep navy/black backgrounds with neon cyan (`#00f3ff`) and purple (`#bc13fe`) accents |
| **Glassmorphism** | Frosted glass panels with `backdrop-blur`, subtle borders, and transparency |
| **3D Interactions** | Perspective-transform card tilts on mouse movement, animated 3D logo rotation |
| **Micro-Animations** | Framer Motion staggered reveals, hover scale effects, smooth transitions |
| **Particle Effects** | Floating animated particles with randomized paths and glow orbs |
| **Data Density** | 2Ã—2 grid layout maximizing information display across 4 interactive panels |

</div>

<br/>

<div align="center">
<img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">
</div>

<br/>

## ğŸ¤ Contributing

Contributions are welcome! Feel free to open issues or submit pull requests.

1. **Fork** the repository
2. **Create** your feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to the branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

<br/>

## ğŸ“œ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

<br/>

## ğŸ‘¤ Author

<div align="center">

**Aayush Patel**

[![GitHub](https://img.shields.io/badge/GitHub-itsAayushhh-181717?style=for-the-badge&logo=github)](https://github.com/itsAayushhh)

</div>

<br/>

<div align="center">

<img src="https://capsule-render.vercel.app/api?type=waving&color=0:0a0a20,50:00f3ff,100:bc13fe&height=120&section=footer&animation=fadeIn" width="100%" />

<br/>

<sub>Built with ğŸ§  intelligence and ğŸ’œ passion</sub>

</div>
